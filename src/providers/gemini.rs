use anyhow::{anyhow, Result};
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use crate::providers::{Provider, Role, Message, Model};

/// Implementation of the Gemini provider
#[derive(Debug)]
pub struct GeminiProvider {
    api_key: String,
    models: Vec<Model>,
}

impl GeminiProvider {
    /// Creates a new Gemini provider instance
    pub fn new(api_key: &str, models: Vec<Model>) -> Self {
        GeminiProvider {
            api_key: api_key.to_string(),
            models,
        }
    }
}

#[async_trait]
impl Provider for GeminiProvider {
    fn name(&self) -> &str {
        "Gemini"
    }

    fn models(&self) -> Vec<Model> {
        self.models.clone()
    }

    async fn generate_response(
        &self,
        model: &Model,
        history: &VecDeque<Message>,
        context: &str,
    ) -> Result<String> {
        let client = reqwest::Client::new();
        
        // Prepare contents for Gemini API
        let mut contents = Vec::new();
        
        // Add system context as the first content
        contents.push(Content {
            parts: vec![Part {
                text: format!("You are an expert coding assistant. Context:\n{}", context),
            }],
        });
        
        // Add conversation history
        for message in history {
            let content_text = match message.role {
                Role::System => format!("System: {}", message.content),
                Role::User => format!("User: {}", message.content),
                Role::Assistant => format!("Assistant: {}", message.content),
                Role::Tool => format!("Tool: {}", message.content),
            };
            
            contents.push(Content {
                parts: vec![Part { text: content_text }],
            });
        }

        // Prepare request payload
        let payload = GeminiRequest {
            contents,
            generation_config: Some(GenerationConfig {
                max_output_tokens: Some(model.default_max_tokens as i32),
                temperature: Some(0.7),
            }),
        };

        // Build API URL
        let url = format!(
            "https://generativelanguage.googleapis.com/v1beta/models/{}:generateContent?key={}",
            model.id, self.api_key
        );

        // Send request to Gemini API
        let response = client
            .post(&url)
            .json(&payload)
            .send()
            .await?;

        // Check for HTTP errors
        if !response.status().is_success() {
            let status = response.status();
            let body = response.text().await?;
            return Err(anyhow!(
                "Gemini API error: {} - {}",
                status,
                body
            ));
        }

        let response_body: GeminiResponse = response.json().await?;

        // Extract generated text
        response_body
            .candidates
            .first()
            .and_then(|c| c.content.parts.first().map(|p| p.text.clone()))
            .ok_or_else(|| anyhow!("No text generated by Gemini"))
    }
}

// Request and response structures
#[derive(Serialize, Debug)]
struct GeminiRequest {
    contents: Vec<Content>,
    #[serde(rename = "generationConfig", skip_serializing_if = "Option::is_none")]
    generation_config: Option<GenerationConfig>,
}

#[derive(Serialize, Debug)]
struct GenerationConfig {
    #[serde(rename = "maxOutputTokens", skip_serializing_if = "Option::is_none")]
    max_output_tokens: Option<i32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    temperature: Option<f32>,
}

#[derive(Serialize, Deserialize, Debug)]
struct Content {
    parts: Vec<Part>,
}

#[derive(Serialize, Deserialize, Debug)]
struct Part {
    text: String,
}

#[derive(Deserialize, Debug)]
struct GeminiResponse {
    candidates: Vec<Candidate>,
}

#[derive(Deserialize, Debug)]
struct Candidate {
    content: Content,
}